{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "oy2Bz9CYtBir"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AUTO GRAD\n",
        "y = torch.tensor(2.0,requires_grad=True)\n",
        "\n",
        "x = y ** 2 + y*2 + 1\n",
        "\n",
        "z = x ** 3"
      ],
      "metadata": {
        "id": "TWvX7ieFPFWW"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.backward()"
      ],
      "metadata": {
        "id": "IP79g_j1PTuq"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad,x.grad"
      ],
      "metadata": {
        "id": "rwe-qwUBPffB",
        "outputId": "31990d94-17a7-4a48-ef9f-3ff5e9f7dd6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-104-bde24807d4bc>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  y.grad,x.grad\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1458.), None)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# why we need to zero grad\n",
        "x = torch.tensor(2.0,dtype=torch.float32,requires_grad=True)"
      ],
      "metadata": {
        "id": "frRKXLA6NwlQ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets run it for 4 epochs\n",
        "for i in range(4):\n",
        "  y = x**2\n",
        "  y.backward()\n",
        "  print(x.grad)"
      ],
      "metadata": {
        "id": "HI3dVf_wOH1z",
        "outputId": "c34b777b-3ae5-4d8f-d623-f8d06c6a0ea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n",
            "tensor(8.)\n",
            "tensor(12.)\n",
            "tensor(16.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()"
      ],
      "metadata": {
        "id": "T-PpX0j9ONyT",
        "outputId": "ed1407c7-912b-4916-92ff-243ad69ba860",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lPU4nKFeOamq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}